{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot.ipynb","provenance":[{"file_id":"1W-8BIJMFUzFvwoJGppIDibFtXchnKINM","timestamp":1591750099931}],"collapsed_sections":[],"authorship_tag":"ABX9TyOtG2XmBKxnmDo/lAt5NDqd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"s1XZKYnfstX5","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5mPydtLtR1P","colab_type":"code","colab":{}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wG308C0tjlm","colab_type":"code","colab":{}},"source":["import os\n","local_download_path = os.path.expanduser('~/data')\n","try:\n","  os.makedirs(local_download_path)\n","except: pass\n","\n","file_list = drive.ListFile(\n","    {'q': \"'1oNbj4ZG7JgzZqOtb2e8ut9H7bdOWjI7e' in parents\"}).GetList()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzbEsTZCtpxl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"status":"ok","timestamp":1594771118755,"user_tz":-330,"elapsed":45421,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"8813d62c-d8b6-4a5c-eceb-efef9d2282da"},"source":["for f in file_list:\n","  print('title: %s, id: %s' % (f['title'], f['id']))\n","  fname = os.path.join(local_download_path, f['title'])\n","  print('downloading to {}'.format(fname))\n","  f_ = drive.CreateFile({'id': f['id']})\n","  f_.GetContentFile(fname)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["title: Chatbot.ipynb, id: 1HNDPoG5qyjkhS5aMvbW4XIBWpLymUox-\n","downloading to /root/data/Chatbot.ipynb\n","title: Chatbot using 2 GRU.ipynb, id: 1wGq3QW-ezGZE-hymmjMwxAwXsEyipSX0\n","downloading to /root/data/Chatbot using 2 GRU.ipynb\n","title: Copy of Chatbot using 2 GRU.ipynb, id: 1m-68GmQ29BnPhiMSxlhgTGIkFL9Y0sBt\n","downloading to /root/data/Copy of Chatbot using 2 GRU.ipynb\n","title: Deep-Learning-with-PyTorch.pdf, id: 1vfT6ar4ImU9ppBjxJXeTG1FLNRJC2yPZ\n","downloading to /root/data/Deep-Learning-with-PyTorch.pdf\n","title: Untitled1.ipynb, id: 1XA_l-6JG977k0MRpk9qZbutJ7xA7_cOr\n","downloading to /root/data/Untitled1.ipynb\n","title: Copy of 01_Simple_Linear_Model.ipynb, id: 1eIjxXCRjPqJbBIde1XoguSmHjTv_2hrL\n","downloading to /root/data/Copy of 01_Simple_Linear_Model.ipynb\n","title: mnist.ipynb, id: 1lVycd2-6Llcoa9vwEMlvB6hTbKVCdNzB\n","downloading to /root/data/mnist.ipynb\n","title: dataset.ipynb, id: 1IcYqMPCCBr1RRUJrHtZEpczlciyacEGf\n","downloading to /root/data/dataset.ipynb\n","title: Untitled0.ipynb, id: 1nXY9d1lef14xnj7cDSQwxwY9oUTq9qIO\n","downloading to /root/data/Untitled0.ipynb\n","title: Untitled, id: 1ELgkQGrwN9WpitKwoXQLL3Liy4Bg99mS\n","downloading to /root/data/Untitled\n","title: cornell_movie_dialogs_corpus.zip, id: 1tSMMXQUnEWbytc5VSbC-SJx-Z5NtdY7g\n","downloading to /root/data/cornell_movie_dialogs_corpus.zip\n","title: names_train.csv.gz, id: 1Gm0gAWRrdC1ctwz37Pu7SqzfoLUPgEVI\n","downloading to /root/data/names_train.csv.gz\n","title: names_test.csv.gz, id: 1iM8LdJtCsf5OI5vUcbDbEPsLkl8eA8Pm\n","downloading to /root/data/names_test.csv.gz\n","title: Copy of Copy of NMT_icode.ipynb, id: 1teNut24mzKjH_PP1NUz1-Z3qIfe73IMv\n","downloading to /root/data/Copy of Copy of NMT_icode.ipynb\n","title: Word2Vec.ipynb, id: 1X-QeDuYpOLu00phXzZl4Au4kjhmdnEOF\n","downloading to /root/data/Word2Vec.ipynb\n","title: Copy of Kaggle API access example.ipynb, id: 17Khx8CbfL6UMFDb_uH8ZMLplIXc64XdU\n","downloading to /root/data/Copy of Kaggle API access example.ipynb\n","title: exploring_word_vectors-checkpoint.ipynb, id: 1sg7pkgPpF4MvqVQoKLJXwjvWYou2vv5h\n","downloading to /root/data/exploring_word_vectors-checkpoint.ipynb\n","title: Classification Decision Tree.ipynb, id: 1BXFuzQVzcY7SadldHKMXvAJaHqETdXcf\n","downloading to /root/data/Classification Decision Tree.ipynb\n","title: Cafe Resturant.ipynb, id: 1sb-iY1gXHbt1HVSfSYOz_3ypcS6p7Y_g\n","downloading to /root/data/Cafe Resturant.ipynb\n","title: Capstone.ipynb, id: 1qUUgcbnxlDOk3n3u9A8lqUCB_YRVc5vZ\n","downloading to /root/data/Capstone.ipynb\n","title: Copy of Untitled0.ipynb, id: 14PMzUXXzDccG3VL2ENY_65QqquRXymFg\n","downloading to /root/data/Copy of Untitled0.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4nRu2Y4mtxZp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1594771133083,"user_tz":-330,"elapsed":3346,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"eeb8f6cb-7edd-4b0c-c62b-20c6e9869bfe"},"source":["!unzip /root/data/cornell_movie_dialogs_corpus.zip -d '/root/data'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  /root/data/cornell_movie_dialogs_corpus.zip\n","   creating: /root/data/cornell movie-dialogs corpus/\n","  inflating: /root/data/cornell movie-dialogs corpus/.DS_Store  \n","   creating: /root/data/__MACOSX/\n","   creating: /root/data/__MACOSX/cornell movie-dialogs corpus/\n","  inflating: /root/data/__MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n","  inflating: /root/data/cornell movie-dialogs corpus/chameleons.pdf  \n","  inflating: /root/data/__MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n","  inflating: /root/data/cornell movie-dialogs corpus/movie_characters_metadata.txt  \n","  inflating: /root/data/cornell movie-dialogs corpus/movie_conversations.txt  \n","  inflating: /root/data/cornell movie-dialogs corpus/movie_lines.txt  \n","  inflating: /root/data/cornell movie-dialogs corpus/movie_titles_metadata.txt  \n","  inflating: /root/data/cornell movie-dialogs corpus/raw_script_urls.txt  \n","  inflating: /root/data/cornell movie-dialogs corpus/README.txt  \n","  inflating: /root/data/__MACOSX/cornell movie-dialogs corpus/._README.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dfZ7OeR-uVPG","colab_type":"code","colab":{}},"source":["readme = open('/root/data/cornell movie-dialogs corpus/README.txt',encoding='utf-8',errors='ignore').read().split('\\n')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U38AoNZKujdj","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import unicode_literals\n","\n","import torch\n","from torch.jit import script, trace\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import csv\n","import random\n","import re\n","import os\n","import unicodedata\n","import codecs\n","from io import open\n","import itertools\n","import math\n","\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ek4kd4kDupag","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"ok","timestamp":1594771150669,"user_tz":-330,"elapsed":1216,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"b3e47708-46da-407b-9075-9b59a74bc868"},"source":["corpus_name = \"cornell movie-dialogs corpus\"\n","corpus = os.path.join(\"/root/data\", corpus_name)\n","\n","def printLines(file, n=10):\n","    with open(file, 'rb') as datafile:\n","        lines = datafile.readlines()\n","    for line in lines[:n]:\n","        print(line)\n","\n","printLines(os.path.join(corpus, \"movie_lines.txt\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n","b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n","b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n","b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n","b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n","b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n","b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n","b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n","b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n","b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"esjhnFXHu0NV","colab_type":"code","colab":{}},"source":["# Splits each line of the file into a dictionary of fields\n","def loadLines(fileName, fields):\n","    lines = {}\n","    with open(fileName, 'r', encoding='iso-8859-1') as f:\n","        for line in f:\n","            values = line.split(\" +++$+++ \")\n","            # Extract fields\n","            lineObj = {}\n","            for i, field in enumerate(fields):\n","                lineObj[field] = values[i]\n","            lines[lineObj['lineID']] = lineObj\n","    return lines\n","# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n","def loadConversations(fileName, lines, fields):\n","    conversations = []\n","    with open(fileName, 'r', encoding='iso-8859-1') as f:\n","        for line in f:\n","            values = line.split(\" +++$+++ \")\n","            # Extract fields\n","            convObj = {}\n","            for i, field in enumerate(fields):\n","                convObj[field] = values[i]\n","            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n","            utterance_id_pattern = re.compile('L[0-9]+')\n","            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n","            # Reassemble lines\n","            convObj[\"lines\"] = []\n","            for lineId in lineIds:\n","                convObj[\"lines\"].append(lines[lineId])\n","            conversations.append(convObj)\n","    return conversations\n","# Extracts pairs of sentences from conversations\n","def extractSentencePairs(conversations):\n","    qa_pairs = []\n","    for conversation in conversations:\n","        # Iterate over all the lines of the conversation\n","        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n","            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n","            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n","            # Filter wrong samples (if one of the lists is empty)\n","            if inputLine and targetLine:\n","                qa_pairs.append([inputLine, targetLine])\n","    return qa_pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzLKiLEWwbLj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1594771169738,"user_tz":-330,"elapsed":2139,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"3921a77f-51f4-4f55-a2ce-245a5f6a4240"},"source":["# Define path to new file\n","datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n","\n","delimiter = '\\t'\n","# Unescape the delimiter\n","delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n","\n","# Initialize lines dict, conversations list, and field ids\n","lines = {}\n","conversations = []\n","MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n","MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n","\n","# Load lines and process conversations\n","print(\"\\nProcessing corpus...\")\n","lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n","print(\"\\nLoading conversations...\")\n","conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n","                                  lines, MOVIE_CONVERSATIONS_FIELDS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Processing corpus...\n","\n","Loading conversations...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jRQAL86UtjT6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1594777454256,"user_tz":-330,"elapsed":1458,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"3792b4ad-740f-4d54-9ad0-834cafa95602"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C-qR-_ym1qzJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594771179276,"user_tz":-330,"elapsed":2373,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"b3c3c9d5-57ff-4330-8eb4-dc885a7019ba"},"source":["# Write new csv file\n","print(\"\\nWriting newly formatted file...\")\n","#with open('/content/gdrive/My Drive/Colab Notebooks/cornell_formattedfile.csv', 'w', encoding='utf-8') as outputfile:\n","with open(datafile, 'w', encoding='utf-8') as outputfile:\n","    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n","    for pair in extractSentencePairs(conversations):\n","        writer.writerow(pair)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Writing newly formatted file...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kp5bHUr8yJCh","colab_type":"code","colab":{}},"source":["PAD_token = 0  # Used for padding short sentences\n","SOS_token = 1  # Start-of-sentence token\n","EOS_token = 2  # End-of-sentence token\n","\n","class Voc:\n","    def __init__(self, name):\n","        self.name = name\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3  # Count SOS, EOS, PAD\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    # Remove words below a certain count threshold\n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Reinitialize dictionaries\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3 # Count default tokens\n","\n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbM3DrEQzP76","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"ok","timestamp":1594771206050,"user_tz":-330,"elapsed":14405,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"ba168e0e-58e9-4407-b977-6ab259265beb"},"source":["MAX_LENGTH = 10  # Maximum sentence length to consider\n","corpus_name = \"cornell movie-dialogs corpus\"\n","corpus = os.path.join(\"/root/data\", corpus_name)\n","# Turn a Unicode string to plain ASCII, thanks to\n","# https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","# Read query/response pairs and return a voc object\n","def readVocs(datafile, corpus_name):\n","    print(\"Reading lines...\")\n","    # Read the file and split into lines\n","    lines = open(datafile, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","    voc = Voc(corpus_name)\n","    return voc, pairs\n","\n","# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n","def filterPair(p):\n","    # Input sequences need to preserve the last word for EOS token\n","    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n","\n","# Filter pairs using filterPair condition\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","# Using the functions defined above, return a populated voc object and pairs list\n","def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n","    print(\"Start preparing training data ...\")\n","    voc, pairs = readVocs(datafile, corpus_name)\n","    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","    print(\"Counted words:\", voc.num_words)\n","    return voc, pairs\n","\n","\n","# Load/Assemble voc and pairs\n","save_dir = '/content/gdrive/My Drive/Colab Notebooks'\n","voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n","# Print some pairs to validate\n","print(\"\\npairs:\")\n","for pair in pairs[:10]:\n","    print(pair)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start preparing training data ...\n","Reading lines...\n","Read 221282 sentence pairs\n","Trimmed to 64271 sentence pairs\n","Counting words...\n","Counted words: 18008\n","\n","pairs:\n","['there .', 'where ?']\n","['you have my word . as a gentleman', 'you re sweet .']\n","['hi .', 'looks like things worked out tonight huh ?']\n","['you know chastity ?', 'i believe we share an art instructor']\n","['have fun tonight ?', 'tons']\n","['well no . . .', 'then that s all you had to say .']\n","['then that s all you had to say .', 'but']\n","['but', 'you always been this selfish ?']\n","['do you listen to this crap ?', 'what crap ?']\n","['what good stuff ?', 'the real you .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1aMDF4Qv48v3","colab_type":"code","colab":{}},"source":["print(voc.index2word[4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_uDoK0CW2o0S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594771242338,"user_tz":-330,"elapsed":23960,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"e8ef0541-9347-4a76-eb81-1c2e0f718f61"},"source":["MIN_COUNT = 3    # Minimum word count threshold for trimming\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Trim words used under the MIN_COUNT from the voc\n","    voc.trim(MIN_COUNT)\n","    # Filter out pairs with trimmed words\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Check input sentence\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Check output sentence\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Trim voc and pairs\n","pairs = trimRareWords(voc, pairs, MIN_COUNT)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["keep_words 7823 / 18005 = 0.4345\n","Trimmed from 64271 pairs to 53165, 0.8272 of total\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_VCwm3-g9Cik","colab_type":"code","colab":{}},"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n","\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.BoolTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyxOroqL9wyu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":490},"executionInfo":{"status":"ok","timestamp":1594771255939,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"dcd22015-e9ee-42ee-9380-7e4aad422187"},"source":["# Example for validation\n","small_batch_size = 5\n","batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n","#batches = batch2TrainData(voc, 'This is a bag')\n","input_variable, lengths, target_variable, mask, max_target_len = batches\n","\n","print(\"input_variable:\", input_variable)\n","print(\"lengths:\", lengths)\n","print(\"target_variable:\", target_variable)\n","print(\"mask:\", mask)\n","print(\"max_target_len:\", max_target_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["input_variable: tensor([[  65, 1864,   50,    5,  318],\n","        [ 197,    4,    7,  115,  997],\n","        [ 117, 1864,   41,  101,    4],\n","        [ 547,    4,    6,    6,    2],\n","        [  12, 1864,    2,    2,    0],\n","        [ 140,    4,    0,    0,    0],\n","        [  98,    4,    0,    0,    0],\n","        [  36,    4,    0,    0,    0],\n","        [   4,    2,    0,    0,    0],\n","        [   2,    0,    0,    0,    0]])\n","lengths: tensor([10,  9,  5,  5,  4])\n","target_variable: tensor([[ 124,   50,   59,   50,   51],\n","        [  65,    6,  357,   92,    4],\n","        [ 197,    2, 1437,    7,    2],\n","        [ 117,    0,  380,  509,    0],\n","        [   6,    0, 6272,   47,    0],\n","        [   2,    0,    2,    6,    0],\n","        [   0,    0,    0,    2,    0]])\n","mask: tensor([[ True,  True,  True,  True,  True],\n","        [ True,  True,  True,  True,  True],\n","        [ True,  True,  True,  True,  True],\n","        [ True, False,  True,  True, False],\n","        [ True, False,  True,  True, False],\n","        [ True, False,  True,  True, False],\n","        [False, False, False,  True, False]])\n","max_target_len: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RzkVdkDP-q8U","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self,hidden_size, embedding, n_layers=1, dropout=0):\n","        super(EncoderRNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embedding = embedding\n","        #self.embedding = nn.Embedding(input_size,hidden_size)\n","        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n","        #   because our input size is a word embedding with number of features == hidden_size\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n","                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n","\n","    def forward(self, input_seq, input_lengths, hidden=None):\n","        # Convert word indexes to embeddings\n","        embedded = self.embedding(input_seq)\n","        # Pack padded batch of sequences for RNN module\n","        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        # Forward pass through GRU\n","        outputs, hidden = self.gru(packed, hidden)\n","        # Unpack padding\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n","        # Sum bidirectional GRU outputs\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        # Return output and final hidden state\n","        return outputs, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsxcQHrM_DBt","colab_type":"code","colab":{}},"source":["class Attn(nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtWLGI3f_WnS","colab_type":"code","colab":{}},"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQOEQSFn_eLG","colab_type":"code","colab":{}},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Jetrcap_4a6","colab_type":"code","colab":{}},"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n","\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    lengths = lengths.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropatation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdEulXcJHZzm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594780903644,"user_tz":-330,"elapsed":1154,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}}},"source":["def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n","\n","    # Load batches for each iteration\n","    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n","                      for _ in range(n_iteration)]\n","\n","    # Initializations\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Training loop\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Extract fields from batch\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Run a training iteration with batch\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Print progress\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","        #save_dir = 'content/content/gdrive/My Drive/Colab Notebooks'\n","        save_dir = F\"/content/drive/My Drive/{model_name}/{corpus_name}\"\n","        \n","        # Save checkpoint\n","        if (iteration % save_every == 0):\n","            print('Saving the checkpoint file')\n","            directory = os.path.join(save_dir,'{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","            print(directory)\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            torch.save({\n","                'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                'en_opt': encoder_optimizer.state_dict(),\n","                'de_opt': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, F\"{directory}/{iteration}_checkpoint.tar\")\n"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"No-nblCwBnsY","colab_type":"code","colab":{}},"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length):\n","        # Forward input through encoder model\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Initialize decoder input with SOS_token\n","        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n","        # Initialize tensors to append decoded words to\n","        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=device)\n","        # Iteratively decode one word token at a time\n","        for _ in range(max_length):\n","            # Forward pass through decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            # Obtain most likely word token and its softmax score\n","            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","            # Record token and score\n","            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","            # Prepare current token to be next decoder input (add a dimension)\n","            decoder_input = torch.unsqueeze(decoder_input, 0)\n","        # Return collections of word tokens and scores\n","        return all_tokens, all_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Pa9WfqWBs95","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n","    ### Format input sentence as a batch\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Create lengths tensor\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Transpose dimensions of batch to match models' expectations\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Use appropriate device\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(device)\n","    # Decode sentence with searcher\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Get input sentence\n","            input_sentence = input('> ')\n","            # Check if it is quit case\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalize sentence\n","            input_sentence = normalizeString(input_sentence)\n","            # Evaluate sentence\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            # Format and print response sentence\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            print('Bot:', ' '.join(output_words))\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2qdOwZxGsdi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594778914115,"user_tz":-330,"elapsed":1405,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"0e2133dd-b817-4d4f-ab3d-99a6afa05d35"},"source":["model_name = 'cb_model'\n","attn_model = 'dot'\n","#attn_model = 'general'\n","#attn_model = 'concat'\n","input_size = 1024\n","hidden_size = 1024\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.9\n","batch_size = 256\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","loadFilename = None\n","checkpoint_iter = 2000\n","#save_dir1= '/content/content/gdrive/My Drive/Colab Notebooks'\n","#loadFilename = os.path.join(save_dir1, model_name, corpus_name,\n","#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n","#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n","\n","\n","# Load model if a loadFilename is provided\n","if loadFilename:\n","    # If loading on same machine the model was trained on\n","    checkpoint = torch.load(loadFilename)\n","    # If loading a model trained on GPU to CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","\n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Initialize encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nYuKN_HrGyTG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":308},"executionInfo":{"status":"ok","timestamp":1594781550482,"user_tz":-330,"elapsed":639546,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"07a63829-6a5f-48d0-83b6-258f899f7075"},"source":["clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 9.0\n","n_iteration = 4000\n","#n_iteration = 10\n","print_every = 1000\n","save_every = 1000\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","# If you have cuda, configure cuda to call\n","for state in encoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","for state in decoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n","           print_every, save_every, clip, corpus_name, loadFilename)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Building optimizers ...\n","Starting Training!\n","Initializing ...\n","Training...\n","Iteration: 1000; Percent complete: 25.0%; Average loss: 0.5843\n","Saving the checkpoint file\n","/content/drive/My Drive/cb_model/cornell movie-dialogs corpus/2-2_1024\n","Iteration: 2000; Percent complete: 50.0%; Average loss: 0.5179\n","Saving the checkpoint file\n","/content/drive/My Drive/cb_model/cornell movie-dialogs corpus/2-2_1024\n","Iteration: 3000; Percent complete: 75.0%; Average loss: 0.4758\n","Saving the checkpoint file\n","/content/drive/My Drive/cb_model/cornell movie-dialogs corpus/2-2_1024\n","Iteration: 4000; Percent complete: 100.0%; Average loss: 0.4516\n","Saving the checkpoint file\n","/content/drive/My Drive/cb_model/cornell movie-dialogs corpus/2-2_1024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ONa_VB43SEBl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1594780728015,"user_tz":-330,"elapsed":45538,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}},"outputId":"69647526-055c-437f-99da-148f063bd271"},"source":["drive.mount('/content/drive', force_remount=True)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m1pkinD7eVna","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594781742606,"user_tz":-330,"elapsed":1323,"user":{"displayName":"Bharathi Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiimHg6aD7D6snLivqnRPeY1gjs76XGeDt4Va_ir6M=s64","userId":"14632047622231090730"}}},"source":["encoder.eval()\n","decoder.eval()\n","\n","# Initialize search module\n","searcher = GreedySearchDecoder(encoder, decoder)"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTjNijI1P894","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"2204f01c-e2d5-4859-c009-4e4e81c58b4b"},"source":["evaluateInput(encoder, decoder, searcher, voc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Bot: hi . . . . . . .\n","Bot: fine son . . . !\n","Bot: don t give her your name . .\n","Bot: just the man . a minute . .\n","Bot: in new york . you ?\n","Bot: in in . . . .\n","Bot: i don t know . me .\n","Bot: no . . . ? ?\n","Bot: what ? what do you mean ?\n","Bot: i d think there . and there .\n","Bot: i m sorry . on . .\n"],"name":"stdout"}]}]}